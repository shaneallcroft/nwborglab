#!!! This file was automatically generated by nwborg !!!
# Code generated primarily from the parsing of: 
#   - sessionskeletons.org
#   - sensors/ultracortex.org
import pynwb
import os
import argparse
from pynwb import NWBHDF5IO
from pynwb import NWBFile
from datetime import datetime
from orgutils import orgutils

def main():
    nwborg_root_path = '/'.join(os.path.dirname(os.path.realpath(__file__)).split('/')[:-2])+'/'
    overview = orgutils.orgToDict(filename=os.path.join(nwborg_root_path,'overview.org'))
    skeleton = orgutils.orgToDict(filename=os.path.join(nwborg_root_path,'sessionskeletons.org'))['emotive_controller']
    parser = argparse.ArgumentParser('Default parser generated automatically by nwborg')
    parser.add_argument('--session-id',type=str,default=-1,help='id for the session being run')
    args,unknown = parser.parse_known_args()
    session_id = args.session_id
    session_path = nwborg_root_path + 'sessions/emotive_controller/' + session_id + '/'
    nwbfile = NWBFile(session_description=skeleton['description'],identifier=session_id,session_start_time=datetime.now(),file_create_date=datetime.today())
    print('nwborg root path: ', nwborg_root_path)
    session_dict = orgutils.orgToDict(filename=session_path+'session.org')
    from brainflow.data_filter import DataFilter
    import numpy as np
    from scipy.stats import entropy
    # emotive controller initial:
    parser.add_argument('--pipe-path', type=str, help='the path to the controller input pipe',
                          required=False, default='/home/shaneallcroft/.local/share/dolphin-emu/Pipes/pipe1')
    parser.add_argument('--debug', type=int, help='the path to the controller input pipe',required=False, default=0)
    args, unknown = parser.parse_known_args()
    pipe_path = args.pipe_path
    print('post session skeleton initial parsing args:', args)
    subject_id = session_dict['subject roles']['player']['subject id']
    # REAL ACTUAL TODO make the savestates for the game and save them in experiment/media
    if not os.path.isfile('subjects/' + str(subject_id) + '/calibration_knn.org'):
        print('ERROR calibration knn missing for subject ' + str(subject_id))
        print('calibration knn required for emotive controller use')
        print("run 'nwborg session quickstart calibration' to get started")
        return
    else:
        subject_calibration_knn = orgutils.orgToDict(filename=('subjects/' + str(subject_id) + '/calibration_knn.org'))
        # read in the player's calibration knn
    input('Beginning emotive controller test session, please make sure the subject is wearing the ultracortex headset...')
    input('this test will take video recording, please ensure the webcam is properly setup and the "emotive-controller-test" scene on OBS is properly configured...')
    input('refrain as much as possible from any exagerated or pronounced face muscle activity, including clenching jaw, grinning, etc as this will interfere with the eeg readings...')
    WINDOW_LENGTH = 1000 # at a rate of 250hz this is equal to 4 seconds
    if not args.debug == 1:
        os.system('obs-studio --startrecording --scene "emotive-controller-test"')
        os.system('dolphin-emu -e experiment-media/sms_gcube.nkit.iso -s PATH_TO_SAVE_STATE_1 &') # the & at the end makes it asynchronous
        os.system('dolphin-emu -e experiment-media/sms_gcube.nkit.iso -s PATH_TO_SAVE_STATE_2 &') # the & at the end makes it asynchronous  
        os.system('dolphin-emu -e experiment-media/sms_gcube.nkit.iso -s PATH_TO_SAVE_STATE_3 &') # the & at the end makes it run in parallel
    last_window_end_idx = 0
    brain_input_count = 0
    knn_k = 3 # k value for knn
    calibration_knn_points = [] # 
    for url, calibration_dict in subject_calibration_knn.items():
        video_valence = calibration_dict['VALENCE']
        video_excitation = calibration_dict['EXCITATION']
        for knn_window_idx, knn_window_data in calibration_dict.items():
            if knn_window_idx == 'VALENCE': # pick it up
                continue
            if knn_window_idx == 'EXCITATION':
                continue
            single_knn_point_features = []
            for channel_name, channel_data in knn_window_data.items():      
                single_knn_point_features.append(channel_data['alpha']['entropy'])
                single_knn_point_features.append(channel_data['alpha']['energy'])
                single_knn_point_features.append(channel_data['beta']['entropy'])
                single_knn_point_features.append(channel_data['beta']['energy'])
                single_knn_point_features.append(channel_data['gamma']['entropy'])
                single_knn_point_features.append(channel_data['gamma']['energy'])
                single_knn_point_features.append(channel_data['theta']['entropy'])
                single_knn_point_features.append(channel_data['theta']['energy'])
            #alpha_band = knn_window['channel ' + str(int(knn_window_idx)]
            calibration_knn_points.append({'features' : np.array(single_knn_point_features),
                                           'VALENCE':video_valence,
                                           'EXCITATION':video_excitation})
    
    print('DEBUG subject calibration points: ', calibration_knn_points)
    controller_fifo = open(pipe_path, 'w')
    import brainflow as bf
    from brainflow.board_shim import BoardShim, BrainFlowInputParams
    from brainflow.data_filter import DataFilter, FilterTypes, AggOperations
    import time
    import pynwb
    import numpy as np
    from pynwb import TimeSeries
    #from discrete_wavelet_transform_test
    from pynwb.ecephys import ElectricalSeries
    CYTON_BOARD = 0
    WINDOW_LENGTH = 4.0
    cyton_board = nwbfile.create_device(name='cyton_board')
    ultracortex_config = orgutils.orgToDict(filename=nwborg_root_path+'sensors/ultracortex.org')
    ultracortex_description = ultracortex_config['description']
    
    electrode_group = nwbfile.create_electrode_group('ultracortex',description=ultracortex_description,location="worn on the user's head",device=cyton_board)
    
    idx = 0
    for electrode in ultracortex_config['electrode config'].keys():
        idx += 1
        electrode_description = ultracortex_config['electrode config'][electrode]['description']
        electrode_location = ultracortex_config['electrode config'][electrode]['location']
        nwbfile.add_electrode(id=int(electrode), location=electrode_location, filtering='none',group=electrode_group,x=0.0,y=0.0,z=0.0,imp=float(idx))
    print('hello from inside ultracortex.org initial')
        # arg parse stuff
    # ACTUAL TODO move what you can of this argparse shit into parsing this file
    parser.add_argument('--timeout', type=int, help='timeout for device discovery or connection'
                          , default=0)
    parser.add_argument('--ip-port', type=int, help='ip port', required=False, default=0)
    parser.add_argument('--ip-protocol', type=int, help='ip protocol, check IpProtocolType enum', required=False, default=0)
    parser.add_argument('--ip-address', type=str, help='ip address', required=False, default='')
    parser.add_argument('--serial-port', type=str, help='serial port', required=False, default='/dev/ttyUSB0')
    parser.add_argument('--mac-address', type=str, help='mac address', required=False, default='')
    parser.add_argument('--streamer-params', type=str, help='streamer params', required=False, default='')
    parser.add_argument('--serial-number', type=str, help='serial number', required=False, default='')
    parser.add_argument('--file', type=str, help='file', required=False, default='')
    parser.add_argument('--sample-frequency', type=float, help='how many times per second to sample',
                        default=1.0)
    
    args,unknown = parser.parse_known_args()
    
    # Read into params from args
    params = BrainFlowInputParams()
    params.ip_port = args.ip_port
    params.serial_port = args.serial_port
    params.mac_address = args.mac_address
    params.serial_number = args.serial_number
    params.ip_address = args.ip_address
    params.ip_protocol = args.ip_protocol
    params.timeout = args.timeout
    params.file = args.file
    
    # read other variables in from args
    #pipe_path = args.pipe_path # for the controller
    sleep_duration = 0.05#1.0/float(args.sample_frequency)
    board = BoardShim(CYTON_BOARD, params)
    board.prepare_session()
    
    # board.start_stream() # use this for default options
    board.start_stream(45000,args.streamer_params)
    
    # vvvvv store all the data collected from the board across the session
    nwb_eeg_ts_raw = []
    
    eeg_channels = BoardShim.get_eeg_channels(CYTON_BOARD)  
    sampling_rate = BoardShim.get_sampling_rate(CYTON_BOARD)
    
    channel_1 = [] #np.array([0] * int(sampling_rate * WINDOW_LENGTH))
    channel_2 = [] #np.array([0] * int(sampling_rate * WINDOW_LENGTH))
    channel_3 = [] #np.array([0] * int(sampling_rate * WINDOW_LENGTH))
    channel_4 = [] #np.array([0] * int(sampling_rate * WINDOW_LENGTH))
    channel_5 = [] #np.array([0] * int(sampling_rate * WINDOW_LENGTH))
    channel_6 = [] #np.array([0] * int(sampling_rate * WINDOW_LENGTH))
    channel_7 = [] #np.array([0] * int(sampling_rate * WINDOW_LENGTH))
    channel_8 = []#np.array([0] * int(sampling_rate * WINDOW_LENGTH))  
    try:
        while(True):
            eeg_data = board.get_board_data()
            eeg_formatted = list()
            for i in range(len(eeg_data[0])):
                eeg_formatted.append(list())
            
            for i,data_buffer in enumerate(eeg_data):
                if not i in eeg_channels:
                    continue 
                for x in range(len(data_buffer)):  
                    eeg_formatted[x].append(data_buffer[x])
            #ACTUAL TODO see if there's any needed referencing to the BIAS
            #ACTUAL TODO see if there's any needed AMR business to do here
            print('hello from inside ultracortex.org loop')
            for data_point in eeg_formatted:
                channel_1.append(data_point[0])
                channel_2.append(data_point[1])
                channel_3.append(data_point[2])
                channel_4.append(data_point[3])
                channel_5.append(data_point[4])
                channel_6.append(data_point[5])
                channel_7.append(data_point[6])
                channel_8.append(data_point[7])
            
                nwb_eeg_ts_raw.append(data_point)
            time.sleep(sleep_duration)
            
            # emotive controller loop:
            # requires sensors/ultracortex.org
            # coefficients = datafilter.perform_wavelet_transform(egg_data)
            eeg_data_channel_list = [channel_1,channel_2,channel_3,channel_4,channel_5,channel_6,channel_7,channel_8]
            if len(nwb_eeg_ts_raw) - last_window_end_idx < WINDOW_LENGTH: # window not large enough yet
                print('Session: emotive controller waiting for input' + str(brain_input_count) + ' more data...')
            else:
                knn_feature_point = {}
                current_brain_features = []
                distance_record = {}
                for channel_number, channel in enumerate(eeg_data_channel_list):
                    channel_number = eeg_channels[channel_number]
                    numpy_channel = np.array(channel)[int((len(nwb_eeg_ts_raw) - WINDOW_LENGTH)):len(nwb_eeg_ts_raw)]
                    # REAL ACTUAL TODO if [int((len(nwb_eeg_ts_raw) - WINDOW_LENGTH)):len(nwb_eeg_ts_raw)]
                    # works you have to make sure you're calibrating with consideration to the same kind of window
            
                    # ACTUAL TODO TEST vvvvv change back or investigate further
                    normalized_channel = (numpy_channel - numpy_channel.min()) / (numpy_channel.max() - numpy_channel.min())
                    #^^^^^^ using min-max normalization ^^^^^^
                    window_data = normalized_channel # ACTUAL TODO MAKE SURE YOU SHOULDN"T BE NORMALIZAING HERE INSTEAD
                    alpha_band = window_data.copy()
                    beta_band = window_data.copy()
                    gamma_band = window_data.copy()
                    theta_band = window_data.copy()
                    #print('before theta bandpass:\n',window_data)
                    DataFilter.perform_bandpass(data=theta_band,sampling_rate=250,center_freq=6.0,band_width=4.0,order=1,filter_type=0,ripple=0.0)
                    #print('after theta bandpass:\n',window_data,'\n\n\n')
                    DataFilter.perform_bandpass(data=alpha_band,sampling_rate=250,center_freq=12.0,band_width=8.0,order=1,filter_type=0,ripple=0.0)
                    DataFilter.perform_bandpass(data=beta_band,sampling_rate=250,center_freq=24.0,band_width=16.0,order=1,filter_type=0,ripple=0.0)
                    DataFilter.perform_bandpass(data=gamma_band,sampling_rate=250,center_freq=48.0,band_width=32.0,order=1,filter_type=0,ripple=0.0)
            
                    print(alpha_band)
                    print(beta_band)
                    print(gamma_band)
                    print(theta_band)
                    # if needed you should convert the bands to np again if datafilter doesn't return an np array
                    # REAL ACTUAL TODO you gotta do DWT
                    #print('alpha band: ', alpha_band)
                    #print(entr(list(alpha_band)))
                    knn_feature_point['channel ' + str(channel_number)] = {'alpha' : {'entropy' : entropy(np.square(alpha_band)),
                                                                                      'energy'  : alpha_band.sum() * .004},
                                                                           'beta'  : {'entropy' : entropy(np.square(beta_band)),
                                                                                      'energy'  : beta_band.sum() * .004},
                                                                           'gamma' : {'entropy' : entropy(np.square(gamma_band)),
                                                                                      'energy'  : gamma_band.sum() * .004},
                                                                           'theta' : {'entropy' : entropy(np.square(theta_band)),
                                                                                      'energy'  : theta_band.sum() * .004}}
                    # 
                    # this is prototype formatting
                    current_brain_features.append(knn_feature_point['channel ' + str(channel_number)]['alpha']['entropy'])
                    current_brain_features.append(knn_feature_point['channel ' + str(channel_number)]['alpha']['energy'])
                    current_brain_features.append(knn_feature_point['channel ' + str(channel_number)]['beta']['entropy'])
                    current_brain_features.append(knn_feature_point['channel ' + str(channel_number)]['beta']['energy'])
                    current_brain_features.append(knn_feature_point['channel ' + str(channel_number)]['gamma']['entropy'])
                    current_brain_features.append(knn_feature_point['channel ' + str(channel_number)]['gamma']['energy'])
                    current_brain_features.append(knn_feature_point['channel ' + str(channel_number)]['theta']['entropy'])
                    current_brain_features.append(knn_feature_point['channel ' + str(channel_number)]['theta']['energy'])
            
                    #beta_features = [beta_band/beta_band.sum(axis=1,keepdims=True),]
                    #gamma_features = [gamma_band/gamma_band.sum(axis=1,keepdims=True),]
                    #theta_features = [theta_band/theta_band.sum(axis=1,keepdims=True),]
                    # dist = np.linalg.norm(a-b)
            
                    # use distance_record.keys().sort to iterate over it when it comes time to round up the points
                
                current_brain_features = np.array(current_brain_features)
                for calibration_point in calibration_knn_points:
                    calibration_point_features = calibration_point['features']
                    distance = np.linalg.norm(calibration_point_features - current_brain_features)
                    if not (distance in distance_record.keys()):
                        distance_record[distance] = []
                    distance_record[distance].append(calibration_point)
            
                # find the k closest points
                canon_input_points = []
                for point_distance in distance_record.keys().sort():
                    for point in distance_record[point_distance]:
                        canon_input_points.append(point)
                        if len(canon_input_points) > knn_k:
                            break
                # alright dope, we have the canon points now
                #knn_voting_dict = {'VALENCE' : {}, 'EXCITATION' : {}}
                # TODO ACTUAL TODO FIX THE VOTING PROCESS
                valence_total = 0.0
                excitation_total = 0.0
                for point in canon_input_points:
                    valence_average += point['VALENCE']
                    excitation_average += point['EXCITATION']
                    #if not point['VALENCE'] in knn_voting_dict.keys():
                    #    knn_voting_dict['VALENCE'][point['VALENCE']] = 0
                    #knn_voting_dict['VALENCE'][point['VALENCE']] += 1
                    #if not point['EXCITATION'] in knn_voting_dict.keys():
                    #    knn_voting_dict['EXCITATION'][point['EXCITATION']] = 0
                    #knn_voting_dict['EXCITATION'][point['EXCITATION']] += 1
                controller_x = (float(valence_total) / float(knn_k)) / 9.0 # valence
                controller_y = (float(excitation_total) / float(knn_k)) / 9.0 # excitation
                last_window_end_idx = len(nwb_eeg_ts_raw) # PICK IT UP ^^^^^^^^^^
                controller_fifo.write('SET MAIN ' + str(controller_x)[1:4] + ' ' + str(controller_y)[1:4])
                controller_fifo.flush()
            
    except Exception as e:
        print("\nrecording complete", e)
        board.stop_stream()
        board.release_session()
        # ACTUAL TODO move what you can of this parameters into orgutils parsing this file
        electrode_table_region = nwbfile.create_electrode_table_region(list(range(0,len(ultracortex_config['electrode config'].keys()))), 'all of the ultracortex electrodes')
        nwb_eeg_ts = ElectricalSeries('ultracortex eeg data',nwb_eeg_ts_raw,electrode_table_region,starting_time=0.0,rate=float(sampling_rate),resolution=.001,comments='data read in from an ultracortex mark IV headset', description=skeleton['description'])
        nwbfile.add_acquisition(nwb_eeg_ts)
        # emotive controller terminal:
        controller_fifo.close()
        os.system('cp experiment-media/webcam-recordings-temp/* ' + 'subjects/'+session_dict['subject roles']['player']['subject id'])
        os.system('mv experiment-media/webcam-recordings-temp/* ' + 'sessions/'+session_dict['archetype'] + '/' + str(session_id))
      

    with NWBHDF5IO(str(session_id) + '.nwb', 'w') as io:
        io.write(nwbfile)
if __name__ == '__main__':
    main()
