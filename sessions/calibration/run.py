#!!! This file was automatically generated by nwborg !!!
# Code generated primarily from the parsing of: 
#   - sessionskeletons.org
#   - sensors/ultracortex.org
import pynwb
import os
import argparse
from pynwb import NWBHDF5IO
from pynwb import NWBFile
from datetime import datetime
from orgutils import orgutils

def main():
    nwborg_root_path = '/'.join(os.path.dirname(os.path.realpath(__file__)).split('/')[:-2])+'/'
    overview = orgutils.orgToDict(filename=os.path.join(nwborg_root_path,'overview.org'))
    skeleton = orgutils.orgToDict(filename=os.path.join(nwborg_root_path,'sessionskeletons.org'))['calibration']
    parser = argparse.ArgumentParser('Default parser generated automatically by nwborg')
    parser.add_argument('--session-id',type=str,default=-1,help='id for the session being run')
    args,unknown = parser.parse_known_args()
    session_id = args.session_id
    session_path = nwborg_root_path + 'sessions/calibration/' + session_id + '/'
    nwbfile = NWBFile(session_description=skeleton['description'],identifier=session_id,session_start_time=datetime.now(),file_create_date=datetime.today())
    nwbfile.add_unit_column('valence','the level of valence self reported by the subject after watching the video, on a scale from 1-9. sam rating scale image presented with the question -- experiment-media/sam.png')
    nwbfile.add_unit_column('exitation','the level of valence self reported by the subject after watching the video, on a scale from 1-9. sam rating scale image presented with the question -- experiment-media/sam.png')
    nwbfile.add_unit_column('videourl','URL to the DEAP video')
    nwbfile.add_unit_column('deapemotiontag','the emotion tag on the video')
    print('nwborg root path: ', nwborg_root_path)
    session_dict = orgutils.orgToDict(filename=session_path+'session.org')
    # programmtic implementation based on
    #https://content.iospress.com/download/technology-and-health-care/thc174836?id=technology-and-health-care%2Fthc174836
    
    # ACTUAL TODO add survey about DEAPU
    # ACTUAL TODO add / look into adding nwb processing modules
    # ACTUAL TODO look into making org file in subject folder detailing their progress with the DEAP videos
    from brainflow.data_filter import DataFilter, FilterTypes, AggOperations
    from scipy.stats import entropy
    import pandas as pd
    print('Please select and input a DEAP data-set video for the subject to watch now')
    video_link = input('DEAP video URL...')
    deapemotiontag = input("If avialable, please provide the video's DEAP emotion tag (cheerful, sentimental, calm etc)....")
    if deapemotiontag == '':
        deapemotiontag = '!!!unknown!!!'
    
    print('Please prepare subject for viewing session:')
    print('  - in a separate terminal window navigate to `experiment-media` in your nwborg project root folder and run `feh SAM.png`')
    print('  - Look at the timestamps for the video specified in the DEAP dataset, prepare to play the video starting at the appropriate timestamp')
    print('  - Using a timer or watching the video progress bar, prepare to stop the video at the appropriate timestamp\n')
    input("When you're ready: press Enter in this window. The recording session will begin. Wait 3 seconds and then press the play button to begin playing the video")
    subject_id = session_dict['subject roles']['viewer']['subject id']
    
    if os.path.isfile('subjects/' + str(subject_id) + '/calibration_knn.org'):
        session_knn_points = orgutils.orgToDict(filename=('subjects/' + str(subject_id) + '/calibration_knn.org'))
    else:
        session_knn_points = {}
    feature_point_list = []
    eeg_data_channel_list = []
    import brainflow as bf
    from brainflow.board_shim import BoardShim, BrainFlowInputParams
    from brainflow.data_filter import DataFilter, FilterTypes, AggOperations
    import time
    import pynwb
    import numpy as np
    from pynwb import TimeSeries
    #from discrete_wavelet_transform_test
    from pynwb.ecephys import ElectricalSeries
    CYTON_BOARD = 0
    WINDOW_LENGTH = 4.0
    cyton_board = nwbfile.create_device(name='cyton_board')
    ultracortex_config = orgutils.orgToDict(filename=nwborg_root_path+'sensors/ultracortex.org')
    ultracortex_description = ultracortex_config['description']
    
    electrode_group = nwbfile.create_electrode_group('ultracortex',description=ultracortex_description,location="worn on the user's head",device=cyton_board)
    
    idx = 0
    for electrode in ultracortex_config['electrode config'].keys():
        idx += 1
        electrode_description = ultracortex_config['electrode config'][electrode]['description']
        electrode_location = ultracortex_config['electrode config'][electrode]['location']
        nwbfile.add_electrode(id=int(electrode), location=electrode_location, filtering='none',group=electrode_group,x=0.0,y=0.0,z=0.0,imp=float(idx))
        print('hello from inside ultracortex.org initial')
        # arg parse stuff
        # ACTUAL TODO move what you can of this argparse shit into parsing this file
    parser.add_argument('--timeout', type=int, help='timeout for device discovery or connection'
                        , default=0)
    parser.add_argument('--ip-port', type=int, help='ip port', required=False, default=0)
    parser.add_argument('--ip-protocol', type=int, help='ip protocol, check IpProtocolType enum', required=False, default=0)
    parser.add_argument('--ip-address', type=str, help='ip address', required=False, default='')
    parser.add_argument('--serial-port', type=str, help='serial port', required=False, default='/dev/ttyUSB0')
    parser.add_argument('--mac-address', type=str, help='mac address', required=False, default='')
    parser.add_argument('--streamer-params', type=str, help='streamer params', required=False, default='')
    parser.add_argument('--serial-number', type=str, help='serial number', required=False, default='')
    parser.add_argument('--file', type=str, help='file', required=False, default='')
    parser.add_argument('--sample-frequency', type=float, help='how many times per second to sample',
                        default=1.0)
    
    args,unknown = parser.parse_known_args()
    
    # Read into params from args
    params = BrainFlowInputParams()
    params.ip_port = args.ip_port
    params.serial_port = args.serial_port
    params.mac_address = args.mac_address
    params.serial_number = args.serial_number
    params.ip_address = args.ip_address
    params.ip_protocol = args.ip_protocol
    params.timeout = args.timeout
    params.file = args.file
    
    # read other variables in from args
    #pipe_path = args.pipe_path # for the controller
    sleep_duration = 0.05#1.0/float(args.sample_frequency)
    board = BoardShim(CYTON_BOARD, params)
    board.prepare_session()
    
    # board.start_stream() # use this for default options
    board.start_stream(45000,args.streamer_params)
    
    # vvvvv store all the data collected from the board across the session
    nwb_eeg_ts_raw = []
    
    eeg_channels = BoardShim.get_eeg_channels(CYTON_BOARD)  
    sampling_rate = BoardShim.get_sampling_rate(CYTON_BOARD)
    
    channel_1 = [] #np.array([0] * int(sampling_rate * WINDOW_LENGTH))
    channel_2 = [] #np.array([0] * int(sampling_rate * WINDOW_LENGTH))
    channel_3 = [] #np.array([0] * int(sampling_rate * WINDOW_LENGTH))
    channel_4 = [] #np.array([0] * int(sampling_rate * WINDOW_LENGTH))
    channel_5 = [] #np.array([0] * int(sampling_rate * WINDOW_LENGTH))
    channel_6 = [] #np.array([0] * int(sampling_rate * WINDOW_LENGTH))
    channel_7 = [] #np.array([0] * int(sampling_rate * WINDOW_LENGTH))
    channel_8 = []#np.array([0] * int(sampling_rate * WINDOW_LENGTH))  
    try:
        while(True):
            eeg_data = board.get_board_data()
            eeg_formatted = list()
            for i in range(len(eeg_data[0])):
                eeg_formatted.append(list())
            
            for i,data_buffer in enumerate(eeg_data):
                if not i in eeg_channels:
                    continue 
                for x in range(len(data_buffer)):  
                    eeg_formatted[x].append(data_buffer[x])
                    #ACTUAL TODO see if there's any needed referencing to the BIAS
                    #ACTUAL TODO see if there's any needed AMR business to do here
                    #print('hello from inside ultracortex.org loop')
            for data_point in eeg_formatted:
                #print(data_point)
                channel_1.append(data_point[0])
                channel_2.append(data_point[1])
                channel_3.append(data_point[2])
                channel_4.append(data_point[3])
                channel_5.append(data_point[4])
                channel_6.append(data_point[5])
                channel_7.append(data_point[6])
                channel_8.append(data_point[7])
            
                nwb_eeg_ts_raw.append(data_point)
            time.sleep(sleep_duration)
            
            # the only thing to do in here is make sure the eeg_data_channel list is up to date
            # because the session code is injected after the hardware code, it always will be up to date at the end of each loop iteration
            print(eeg_data)
            eeg_data_channel_list = [channel_1,channel_2,channel_3,channel_4,channel_5,channel_6,channel_7,channel_8]
    except:
        print("\nrecording complete")
        board.stop_stream()
        board.release_session()
        print('session released')
        # ACTUAL TODO move what you can of this parameters into orgutils parsing this file
        electrode_table_region = nwbfile.create_electrode_table_region(list(range(0,len(ultracortex_config['electrode config'].keys()))), 'all of the ultracortex electrodes')
        nwb_eeg_ts = ElectricalSeries('ultracortex eeg data',nwb_eeg_ts_raw,electrode_table_region,starting_time=0.0,rate=float(sampling_rate),resolution=.001,comments='data read in from an ultracortex mark IV headset', description=skeleton['description'])
        nwbfile.add_acquisition(nwb_eeg_ts)
        # actual todo add arguments for the different dimensions
        # session_path
        #if os.path.isfile('subjects/' + str(subject_id) + '/calibration_knn.csv'):
        #    calibration_csv = pd.read_csv('subjects/' + str(subject_id) + '/calibration_knn.csv') # read in the csv 
        #else:
        #    calibration_csv = pd.Dataframe(columns=['alpha_entropy','alpha_energy','beta_entropy','beta_energy','gamma_entropy','gamma_energy','theta_entropy','theta_energy','valence','exitement'])
        # calibration_csv.to_csv('subjects/' + str(subject_id) + '/calibration_knn.csv')
        # enter all the calibration data into the dataframe as rows
        
        
        print('\n(questions for the subject)')
        print('please direct your attention to the emotional scale image and answer the following questions based on your experience watching the video:')
        session_knn_points[video_link] = {}
        sam_valence = input('where do you fall on the top row scale? left to right 1-9, top row (valence)...')
        session_knn_points[video_link]['VALENCE'] = sam_valence
        sam_excitation = input('where do you fall on the middle row scale? left to right 1-9 middle row (excitation)...')
        session_knn_points[video_link]['EXCITATION'] = sam_excitation
        nwbfile.add_unit(id=1,valence=int(sam_valence),exitation=int(sam_excitation),videourl=video_link,deapemotiontag=deapemotiontag)
        
        
        
        # Pick it up, what needs to happen is nwb_eeg_ts needs to be iterated over with half windows of 500 (2 seconds)
        # With features being captured at resolutions of 1 window or 4 seconds 1000 points
        # basically the code from loop translated to be at the end when looping over all this shtuff
        
        half_window_count = int(len(nwb_eeg_ts_raw)/500) # the number of half windows across the frame of the session
        #print(len(nwb_eeg_ts.data))
        #print(len(nwb_eeg_ts_raw))
        print('window count', half_window_count * 2)
        # use channel list
        for window_idx in range(half_window_count):
            if bool(window_idx): # if it isn't the 0 index window
                knn_feature_point = {}
                for channel_number, channel in enumerate(eeg_data_channel_list):
                    channel_number = eeg_channels[channel_number]
                    print(channel_number)
                    numpy_channel = np.array(channel[(window_idx * 500):((window_idx * 500) + 1000)])
        
                    # ACTUAL TODO TEST vvvvv change back or investigate further
                    normalized_channel = (numpy_channel - numpy_channel.min()) / (numpy_channel.max() - numpy_channel.min())
                    #^^^^^^ using min-max normalization ^^^^^^
                    window_data = normalized_channel
                    alpha_band = window_data.copy()
                    beta_band = window_data.copy()
                    gamma_band = window_data.copy()
                    theta_band = window_data.copy()
                    #print('before theta bandpass:\n',window_data)
                    DataFilter.perform_bandpass(data=theta_band,sampling_rate=250,center_freq=6.0,band_width=4.0,order=1,filter_type=0,ripple=0.0)
                    #print('after theta bandpass:\n',window_data,'\n\n\n')
                    DataFilter.perform_bandpass(data=alpha_band,sampling_rate=250,center_freq=12.0,band_width=8.0,order=1,filter_type=0,ripple=0.0)
                    DataFilter.perform_bandpass(data=beta_band,sampling_rate=250,center_freq=24.0,band_width=16.0,order=1,filter_type=0,ripple=0.0)
                    DataFilter.perform_bandpass(data=gamma_band,sampling_rate=250,center_freq=48.0,band_width=32.0,order=1,filter_type=0,ripple=0.0)
        
                    #print(alpha_band)
                    #print(beta_band)
                    #print(gamma_band)
                    #print(theta_band)
                    # if needed you should convert the bands to np again if datafilter doesn't return an np array
                    # REAL ACTUAL TODO you gotta do DWT
                    #print('alpha band: ', alpha_band)
                    #print(entr(list(alpha_band)))
                    knn_feature_point['channel ' + str(channel_number)] = {'alpha' : {'entropy' : entropy(np.square(alpha_band)),
                                                                                      'energy'  : alpha_band.sum() * .004},
                                                                           'beta'  : {'entropy' : entropy(np.square(beta_band)),
                                                                                      'energy'  : beta_band.sum() * .004},
                                                                           'gamma' : {'entropy' : entropy(np.square(gamma_band)),
                                                                                      'energy'  : gamma_band.sum() * .004},
                                                                           'theta' : {'entropy' : entropy(np.square(theta_band)),
                                                                                      'energy'  : theta_band.sum() * .004}}
                    #beta_features = [beta_band/beta_band.sum(axis=1,keepdims=True),]
                    #gamma_features = [gamma_band/gamma_band.sum(axis=1,keepdims=True),]
                    #theta_features = [theta_band/theta_band.sum(axis=1,keepdims=True),]
                    session_knn_points[video_link][str(window_idx)] = knn_feature_point
        orgutils.dictToOrg(org_data=session_knn_points,output_filename=('subjects/' + str(subject_id) + '/calibration_knn.org'))
        
    with NWBHDF5IO(str(session_id) + '.nwb', 'w') as io:
        io.write(nwbfile)
if __name__ == '__main__':
    main()
